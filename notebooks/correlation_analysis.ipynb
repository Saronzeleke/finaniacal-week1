{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Correlation Analysis - Interactive Notebook\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from task3_correlation_analysis import CorrelationAnalyzer\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Task 3: Correlation Analysis between News Sentiment and Stock Returns\")\n",
    "# Section 1: Setup and Data Loading\n",
    "print(\"Loading and preparing data...\")\n",
    "\n",
    "# Initialize the correlation analyzer\n",
    "analyzer = CorrelationAnalyzer(\n",
    "    news_data_path='../data/processed/news_data.csv',\n",
    "    stock_data_path='../data/processed/stock_data.csv'\n",
    ")\n",
    "\n",
    "# Load the data\n",
    "analyzer.load_data()\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"\\nNews Data Overview:\")\n",
    "print(f\"Shape: {analyzer.news_data.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(analyzer.news_data.head())\n",
    "\n",
    "print(\"\\nStock Data Overview:\")\n",
    "print(f\"Shape: {analyzer.stock_data.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(analyzer.stock_data.head())\n",
    "# Section 2: Explore News Data Statistics\n",
    "print(\"News Data Statistics:\")\n",
    "\n",
    "# Basic stats about news data\n",
    "print(f\"Total news articles: {len(analyzer.news_data)}\")\n",
    "print(f\"Date range: {analyzer.news_data['publication_date'].min()} to {analyzer.news_data['publication_date'].max()}\")\n",
    "print(f\"Number of unique dates: {analyzer.news_data['publication_date'].nunique()}\")\n",
    "\n",
    "# Articles per day\n",
    "articles_per_day = analyzer.news_data.groupby('publication_date').size()\n",
    "print(f\"\\nAverage articles per day: {articles_per_day.mean():.2f}\")\n",
    "print(f\"Maximum articles in a day: {articles_per_day.max()}\")\n",
    "print(f\"Minimum articles in a day: {articles_per_day.min()}\")\n",
    "\n",
    "# Plot articles per day\n",
    "plt.figure(figsize=(12, 6))\n",
    "articles_per_day.plot(kind='line', title='Number of News Articles Per Day')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Section 3: Explore Stock Data Statistics\n",
    "print(\"Stock Data Statistics:\")\n",
    "\n",
    "# Basic stats about stock data\n",
    "print(f\"Total trading days: {len(analyzer.stock_data)}\")\n",
    "print(f\"Date range: {analyzer.stock_data['Date'].min()} to {analyzer.stock_data['Date'].max()}\")\n",
    "\n",
    "# Stock price statistics\n",
    "print(f\"\\nStock Price Statistics:\")\n",
    "print(f\"Average Close Price: ${analyzer.stock_data['Close'].mean():.2f}\")\n",
    "print(f\"High: ${analyzer.stock_data['High'].max():.2f}\")\n",
    "print(f\"Low: ${analyzer.stock_data['Low'].min():.2f}\")\n",
    "\n",
    "# Plot stock price movement\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(analyzer.stock_data['Date'], analyzer.stock_data['Close'], linewidth=2)\n",
    "plt.title('Stock Price Movement')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(analyzer.stock_data['Date'], analyzer.stock_data['Volume'], alpha=0.7)\n",
    "plt.title('Trading Volume')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volume')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Section 4: Perform Sentiment Analysis\n",
    "print(\"Performing Sentiment Analysis on News Headlines...\")\n",
    "\n",
    "# Perform sentiment analysis\n",
    "sentiment_data = analyzer.analyze_sentiment()\n",
    "\n",
    "# Display sentiment results\n",
    "print(\"\\nSentiment Analysis Results:\")\n",
    "print(f\"Analyzed {len(analyzer.news_data)} news articles\")\n",
    "print(f\"Generated sentiment for {len(sentiment_data)} days\")\n",
    "\n",
    "print(\"\\nSentiment Statistics:\")\n",
    "print(f\"Average Daily Sentiment: {sentiment_data['avg_sentiment'].mean():.4f}\")\n",
    "print(f\"Sentiment Std Dev: {sentiment_data['avg_sentiment'].std():.4f}\")\n",
    "print(f\"Most Positive Day: {sentiment_data['avg_sentiment'].max():.4f}\")\n",
    "print(f\"Most Negative Day: {sentiment_data['avg_sentiment'].min():.4f}\")\n",
    "\n",
    "# Display sentiment data\n",
    "display(sentiment_data.head(10))# Section 5: Visualize Sentiment Analysis Results\n",
    "print(\"Visualizing Sentiment Analysis Results...\")\n",
    "\n",
    "# Create comprehensive sentiment visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Daily average sentiment over time\n",
    "axes[0, 0].plot(sentiment_data['publication_date'], sentiment_data['avg_sentiment'], \n",
    "                color='blue', linewidth=2, alpha=0.8)\n",
    "axes[0, 0].set_title('Daily Average Sentiment Over Time')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Sentiment Score')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plot 2: Distribution of sentiment scores\n",
    "axes[0, 1].hist(sentiment_data['avg_sentiment'], bins=20, alpha=0.7, \n",
    "                color='green', edgecolor='black')\n",
    "axes[0, 1].set_title('Distribution of Daily Average Sentiment')\n",
    "axes[0, 1].set_xlabel('Sentiment Score')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Articles per day vs sentiment\n",
    "axes[1, 0].scatter(sentiment_data['article_count'], sentiment_data['avg_sentiment'], \n",
    "                   alpha=0.6, color='purple')\n",
    "axes[1, 0].set_title('Articles per Day vs Sentiment')\n",
    "axes[1, 0].set_xlabel('Number of Articles')\n",
    "axes[1, 0].set_ylabel('Average Sentiment')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Sentiment volatility\n",
    "axes[1, 1].plot(sentiment_data['publication_date'], sentiment_data['sentiment_std'], \n",
    "                color='orange', alpha=0.8)\n",
    "axes[1, 1].set_title('Sentiment Volatility (Standard Deviation)')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Sentiment Std Dev')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional: Sentiment heatmap by day of week\n",
    "sentiment_data['day_of_week'] = sentiment_data['publication_date'].dt.day_name()\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "sentiment_by_day = sentiment_data.groupby('day_of_week')['avg_sentiment'].mean().reindex(day_order)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(sentiment_by_day.index, sentiment_by_day.values, color='skyblue', alpha=0.7)\n",
    "plt.title('Average Sentiment by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Average Sentiment Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Section 6: Compute Daily Returns and Prepare for Correlation\n",
    "print(\"Computing Daily Returns and Merging Data...\")\n",
    "\n",
    "# Compute daily returns\n",
    "returns_data = analyzer.compute_daily_returns()\n",
    "\n",
    "print(\"\\nReturns Statistics:\")\n",
    "print(f\"Average Daily Return: {returns_data['daily_return'].mean():.4f}%\")\n",
    "print(f\"Return Std Dev: {returns_data['daily_return'].std():.4f}%\")\n",
    "print(f\"Maximum Daily Return: {returns_data['daily_return'].max():.4f}%\")\n",
    "print(f\"Minimum Daily Return: {returns_data['daily_return'].min():.4f}%\")\n",
    "\n",
    "# Display returns data\n",
    "display(returns_data.head(10))\n",
    "\n",
    "# Plot returns distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(returns_data['daily_return'], bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Daily Returns')\n",
    "plt.xlabel('Daily Return (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(returns_data['Date'], returns_data['daily_return'], alpha=0.7)\n",
    "plt.title('Daily Returns Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Daily Return (%)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Section 7: Merge Sentiment and Returns Data\n",
    "print(\"Merging Sentiment and Returns Data...\")\n",
    "\n",
    "# Merge the datasets\n",
    "merged_data = analyzer.merge_sentiment_returns()\n",
    "\n",
    "print(f\"Merged dataset shape: {merged_data.shape}\")\n",
    "print(f\"Number of matching days with both sentiment and returns: {len(merged_data)}\")\n",
    "\n",
    "# Display merged data\n",
    "print(\"\\nMerged Data Sample:\")\n",
    "display(merged_data.head(10))\n",
    "\n",
    "# Basic statistics of merged data\n",
    "print(\"\\nMerged Dataset Statistics:\")\n",
    "print(f\"Date range: {merged_data['publication_date'].min()} to {merged_data['publication_date'].max()}\")\n",
    "print(f\"Average sentiment: {merged_data['avg_sentiment'].mean():.4f}\")\n",
    "print(f\"Average daily return: {merged_data['daily_return'].mean():.4f}%\")\n",
    "print(f\"Correlation between sentiment and returns: {merged_data['avg_sentiment'].corr(merged_data['daily_return']):.4f}\")\n",
    "# Section 8: Perform Correlation Analysis\n",
    "print(\"Performing Correlation Analysis...\")\n",
    "\n",
    "# Calculate correlation coefficients\n",
    "correlation_results = analyzer.calculate_correlation(merged_data)\n",
    "\n",
    "# Display correlation results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CORRELATION ANALYSIS RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nSample Size: {correlation_results['sample_size']} days\")\n",
    "\n",
    "print(f\"\\nPearson Correlation Coefficients:\")\n",
    "print(f\"Sentiment vs Daily Returns: {correlation_results['daily_return_correlation']:.4f}\")\n",
    "print(f\"P-value: {correlation_results['daily_return_p_value']:.4f}\")\n",
    "\n",
    "print(f\"Sentiment vs Log Returns: {correlation_results['log_return_correlation']:.4f}\")\n",
    "print(f\"P-value: {correlation_results['log_return_p_value']:.4f}\")\n",
    "\n",
    "print(f\"Sentiment vs Next Day Returns: {correlation_results['lagged_correlation']:.4f}\")\n",
    "print(f\"P-value: {correlation_results['lagged_p_value']:.4f}\")\n",
    "\n",
    "# Interpret the results\n",
    "print(f\"\\nINTERPRETATION:\")\n",
    "corr_value = correlation_results['daily_return_correlation']\n",
    "p_value = correlation_results['daily_return_p_value']\n",
    "\n",
    "# Correlation strength\n",
    "if abs(corr_value) < 0.1:\n",
    "    strength = \"negligible\"\n",
    "elif abs(corr_value) < 0.3:\n",
    "    strength = \"weak\"\n",
    "elif abs(corr_value) < 0.5:\n",
    "    strength = \"moderate\"\n",
    "else:\n",
    "    strength = \"strong\"\n",
    "\n",
    "direction = \"positive\" if corr_value > 0 else \"negative\"\n",
    "\n",
    "print(f\"The correlation between news sentiment and stock returns is {strength} and {direction}.\")\n",
    "\n",
    "# Statistical significance\n",
    "if p_value < 0.05:\n",
    "    print(\"The correlation is statistically significant (p < 0.05).\")\n",
    "else:\n",
    "    print(\"The correlation is not statistically significant (p >= 0.05).\")\n",
    "\n",
    "# Additional correlation matrix\n",
    "print(f\"\\nAdditional Correlations:\")\n",
    "correlation_matrix = merged_data[['avg_sentiment', 'daily_return', 'log_return', 'article_count', 'Volume']].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.3f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix: Sentiment, Returns, and Market Factors')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Section 9: Comprehensive Visualization\n",
    "print(\"Generating Comprehensive Visualizations...\")\n",
    "\n",
    "# Generate all visualizations\n",
    "analyzer.visualize_correlation(merged_data, save_path='../results/task3_correlation_analysis.png')\n",
    "\n",
    "# Additional custom visualizations\n",
    "print(\"\\nGenerating Additional Custom Visualizations...\")\n",
    "\n",
    "# 1. Rolling correlation over time\n",
    "window_size = 30  # 30-day rolling window\n",
    "merged_data_sorted = merged_data.sort_values('publication_date').copy()\n",
    "merged_data_sorted['rolling_corr'] = merged_data_sorted['avg_sentiment'].rolling(window=window_size).corr(merged_data_sorted['daily_return'])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(merged_data_sorted['publication_date'], merged_data_sorted['rolling_corr'], \n",
    "         color='purple', linewidth=2)\n",
    "plt.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "plt.title(f'{window_size}-Day Rolling Correlation Between Sentiment and Returns')\n",
    "plt.ylabel('Rolling Correlation')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(merged_data_sorted['publication_date'], merged_data_sorted['avg_sentiment'], \n",
    "         label='Sentiment', alpha=0.7)\n",
    "plt.plot(merged_data_sorted['publication_date'], merged_data_sorted['daily_return'], \n",
    "         label='Returns', alpha=0.7)\n",
    "plt.title('Sentiment and Returns Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Sentiment vs Returns by sentiment categories\n",
    "merged_data['sentiment_category'] = pd.cut(merged_data['avg_sentiment'], \n",
    "                                          bins=[-1, -0.1, 0.1, 1], \n",
    "                                          labels=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=merged_data, x='sentiment_category', y='daily_return')\n",
    "plt.title('Daily Returns by Sentiment Category')\n",
    "plt.xlabel('Sentiment Category')\n",
    "plt.ylabel('Daily Return (%)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 3. Scatter plot with regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=merged_data, x='avg_sentiment', y='daily_return', \n",
    "            scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
    "plt.title(f'Sentiment vs Daily Returns (Correlation: {correlation_results[\"daily_return_correlation\"]:.3f})')\n",
    "plt.xlabel('Average Daily Sentiment')\n",
    "plt.ylabel('Daily Return (%)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Section 10: Advanced Analysis - Lagged Effects\n",
    "print(\"Analyzing Lagged Effects...\")\n",
    "\n",
    "# Create lagged variables for analysis\n",
    "lags = range(0, 6)  # Analyze lags from 0 to 5 days\n",
    "lag_correlations = []\n",
    "\n",
    "for lag in lags:\n",
    "    if lag == 0:\n",
    "        # Same day correlation\n",
    "        corr, p_val = pearsonr(merged_data['avg_sentiment'], merged_data['daily_return'])\n",
    "    else:\n",
    "        # Create lagged returns (sentiment today vs returns in future)\n",
    "        temp_data = merged_data.copy()\n",
    "        temp_data[f'return_lag_{lag}'] = temp_data['daily_return'].shift(-lag)\n",
    "        temp_data_lagged = temp_data.dropna()\n",
    "        \n",
    "        if len(temp_data_lagged) > 0:\n",
    "            corr, p_val = pearsonr(temp_data_lagged['avg_sentiment'], \n",
    "                                 temp_data_lagged[f'return_lag_{lag}'])\n",
    "        else:\n",
    "            corr, p_val = (np.nan, np.nan)\n",
    "    \n",
    "    lag_correlations.append({\n",
    "        'lag_days': lag,\n",
    "        'correlation': corr,\n",
    "        'p_value': p_val,\n",
    "        'significant': p_val < 0.05 if not np.isnan(p_val) else False\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "lag_results = pd.DataFrame(lag_correlations)\n",
    "\n",
    "print(\"Lagged Correlation Analysis:\")\n",
    "display(lag_results)\n",
    "\n",
    "# Plot lagged correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(lag_results['lag_days'], lag_results['correlation'], \n",
    "               color=['red' if sig else 'blue' for sig in lag_results['significant']],\n",
    "               alpha=0.7)\n",
    "\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.title('Correlation Between Sentiment and Future Returns (Lagged Analysis)')\n",
    "plt.xlabel('Lag (Days)')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.xticks(lags)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, corr in zip(bars, lag_results['correlation']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01 * (1 if bar.get_height() > 0 else -1),\n",
    "             f'{corr:.3f}', ha='center', va='bottom' if bar.get_height() > 0 else 'top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Section 11: Save Results and Generate Final Report\n",
    "print(\"Saving Results and Generating Final Report...\")\n",
    "\n",
    "# Save the merged dataset\n",
    "merged_data.to_csv('../data/processed/sentiment_returns_merged.csv', index=False)\n",
    "print(\"Saved merged dataset to: ../data/processed/sentiment_returns_merged.csv\")\n",
    "\n",
    "# Save correlation results\n",
    "correlation_df = pd.DataFrame([correlation_results])\n",
    "correlation_df.to_csv('../results/task3_correlation_results.csv', index=False)\n",
    "print(\"Saved correlation results to: ../results/task3_correlation_results.csv\")\n",
    "\n",
    "# Save lag analysis results\n",
    "lag_results.to_csv('../results/task3_lag_analysis.csv', index=False)\n",
    "print(\"Saved lag analysis results to: ../results/task3_lag_analysis.csv\")\n",
    "\n",
    "# Generate final comprehensive report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TASK 3: FINAL CORRELATION ANALYSIS REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nDATA OVERVIEW:\")\n",
    "print(f\"- News articles analyzed: {len(analyzer.news_data)}\")\n",
    "print(f\"- Trading days analyzed: {len(analyzer.stock_data)}\")\n",
    "print(f\"- Matching days with both sentiment and returns: {len(merged_data)}\")\n",
    "print(f\"- Analysis period: {merged_data['publication_date'].min().strftime('%Y-%m-%d')} to {merged_data['publication_date'].max().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "print(f\"\\nKEY FINDINGS:\")\n",
    "print(f\"1. Primary Correlation (Same Day): {correlation_results['daily_return_correlation']:.4f}\")\n",
    "print(f\"   Statistical Significance: {'Yes' if correlation_results['daily_return_p_value'] < 0.05 else 'No'}\")\n",
    "\n",
    "if not np.isnan(correlation_results['lagged_correlation']):\n",
    "    print(f\"2. Predictive Correlation (Next Day): {correlation_results['lagged_correlation']:.4f}\")\n",
    "    print(f\"   Statistical Significance: {'Yes' if correlation_results['lagged_p_value'] < 0.05 else 'No'}\")\n",
    "\n",
    "print(f\"\\nINTERPRETATION:\")\n",
    "if abs(correlation_results['daily_return_correlation']) > 0.3 and correlation_results['daily_return_p_value'] < 0.05:\n",
    "    print(\"âœ… STRONG EVIDENCE of relationship between news sentiment and stock returns\")\n",
    "elif abs(correlation_results['daily_return_correlation']) > 0.1 and correlation_results['daily_return_p_value'] < 0.05:\n",
    "    print(\"âš ï¸ MODERATE EVIDENCE of relationship between news sentiment and stock returns\")\n",
    "else:\n",
    "    print(\"â• WEAK or NO EVIDENCE of relationship between news sentiment and stock returns\")\n",
    "\n",
    "print(f\"\\nRECOMMENDATIONS:\")\n",
    "if correlation_results['daily_return_p_value'] < 0.05:\n",
    "    if correlation_results['daily_return_correlation'] > 0:\n",
    "        print(\"- Positive news sentiment tends to correlate with positive stock returns\")\n",
    "        print(\"- Consider incorporating sentiment analysis in trading strategies\")\n",
    "    else:\n",
    "        print(\"- Negative news sentiment tends to correlate with negative stock returns\")\n",
    "        print(\"- Sentiment could be used as a contrarian indicator\")\n",
    "else:\n",
    "    print(\"- No statistically significant relationship found\")\n",
    "    print(\"- News sentiment may not be a reliable indicator for this dataset/time period\")\n",
    "\n",
    "print(f\"\\nFILES GENERATED:\")\n",
    "print(\"1. ../data/processed/sentiment_returns_merged.csv - Merged dataset\")\n",
    "print(\"2. ../results/task3_correlation_results.csv - Correlation coefficients\")\n",
    "print(\"3. ../results/task3_lag_analysis.csv - Lagged analysis results\")\n",
    "print(\"4. ../results/task3_correlation_analysis.png - Comprehensive visualizations\")\n",
    "\n",
    "print(f\"\\nTask 3 Correlation Analysis Completed Successfully! ðŸŽ‰\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
