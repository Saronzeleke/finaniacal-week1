{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9885d248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Analysis - Implementing Assessment Criteria\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "print(\"Correlation Analysis - Implementing Assessment Criteria\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a40a605b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading news and stock data...\n",
      "News data loaded: 1407328 records\n",
      "News columns: ['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock']\n",
      "Stock data loaded: 3774 records\n",
      "Stock columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "\n",
      "News data sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>2020-06-05 10:30:54-04:00</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>2020-06-03 10:45:20-04:00</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>2020-05-26 04:30:07-04:00</td>\n",
       "      <td>Lisa Levin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>2020-05-22 12:45:06-04:00</td>\n",
       "      <td>Lisa Levin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>2020-05-22 11:38:59-04:00</td>\n",
       "      <td>Vick Meyer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0            Stocks That Hit 52-Week Highs On Friday   \n",
       "1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2                      71 Biggest Movers From Friday   \n",
       "3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4  B of A Securities Maintains Neutral on Agilent...   \n",
       "\n",
       "                        date          publisher  \n",
       "0  2020-06-05 10:30:54-04:00  Benzinga Insights  \n",
       "1  2020-06-03 10:45:20-04:00  Benzinga Insights  \n",
       "2  2020-05-26 04:30:07-04:00         Lisa Levin  \n",
       "3  2020-05-22 12:45:06-04:00         Lisa Levin  \n",
       "4  2020-05-22 11:38:59-04:00         Vick Meyer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stock data sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>0.199652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>0.203319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>0.210196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-07</td>\n",
       "      <td>0.197589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-08</td>\n",
       "      <td>0.192546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Close\n",
       "0  2009-01-02  0.199652\n",
       "1  2009-01-05  0.203319\n",
       "2  2009-01-06  0.210196\n",
       "3  2009-01-07  0.197589\n",
       "4  2009-01-08  0.192546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and prepare data for correlation analysis\n",
    "print(\"Loading news and stock data...\")\n",
    "\n",
    "# Load news data with correct columns\n",
    "news_df = pd.read_csv(r'C:\\Users\\admin\\finaniacal-week1\\data\\raw_analyst_ratings.csv')\n",
    "print(f\"News data loaded: {len(news_df)} records\")\n",
    "print(\"News columns:\", news_df.columns.tolist())\n",
    "\n",
    "# Load stock data with correct columns  \n",
    "stock_df = pd.read_csv(r'C:\\Users\\admin\\finaniacal-week1\\data\\NVDA.csv')\n",
    "print(f\"Stock data loaded: {len(stock_df)} records\")\n",
    "print(\"Stock columns:\", stock_df.columns.tolist())\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nNews data sample:\")\n",
    "display(news_df[['headline', 'date', 'publisher']].head())\n",
    "\n",
    "print(\"\\nStock data sample:\")\n",
    "display(stock_df[['Date', 'Close']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa34f808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing dates between news and stock data...\n",
      "Date normalization completed:\n",
      "News date range: 2011-04-27 00:00:00-04:00 to 2020-06-11 00:00:00-04:00\n",
      "Stock date range: 2009-01-02 00:00:00 to 2023-12-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalizing dates between news and stock data...\")\n",
    "\n",
    "# Force to string\n",
    "news_df['date'] = news_df['date'].astype(str)\n",
    "\n",
    "# Convert to datetime\n",
    "news_df['date_normalized'] = pd.to_datetime(\n",
    "    news_df['date'],\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Normalize\n",
    "news_df['date_normalized'] = news_df['date_normalized'].dt.floor(\"D\")\n",
    "\n",
    "\n",
    "# STOCK DATA \n",
    "stock_df['Date'] = stock_df['Date'].astype(str)\n",
    "\n",
    "stock_df['date_normalized'] = pd.to_datetime(\n",
    "    stock_df['Date'],\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "stock_df['date_normalized'] = stock_df['date_normalized'].dt.floor(\"D\")\n",
    "\n",
    "\n",
    "print(\"Date normalization completed:\")\n",
    "print(f\"News date range: {news_df['date_normalized'].min()} to {news_df['date_normalized'].max()}\")\n",
    "print(f\"Stock date range: {stock_df['date_normalized'].min()} to {stock_df['date_normalized'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc58291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing sentiment analysis on news headlines...\n"
     ]
    }
   ],
   "source": [
    "#Performing sentiment analysis on news headlines\n",
    "print(\"Performing sentiment analysis on news headlines...\")\n",
    "\n",
    "def calculate_sentiment(text):\n",
    "    \"\"\"Calculate sentiment polarity using TextBlob\"\"\"\n",
    "    try:\n",
    "        return TextBlob(str(text)).sentiment.polarity\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# Apply sentiment analysis to each headline\n",
    "news_df['sentiment'] = news_df['headline'].apply(calculate_sentiment)\n",
    "\n",
    "print(\"Sentiment analysis completed\")\n",
    "print(f\"Sentiment statistics:\")\n",
    "print(f\"  Average sentiment: {news_df['sentiment'].mean():.4f}\")\n",
    "print(f\"  Min sentiment: {news_df['sentiment'].min():.4f}\")\n",
    "print(f\"  Max sentiment: {news_df['sentiment'].max():.4f}\")\n",
    "print(f\"  Std sentiment: {news_df['sentiment'].std():.4f}\")\n",
    "\n",
    "# Display headlines with sentiment scores\n",
    "print(\"\\nSample headlines with sentiment scores:\")\n",
    "sample_news = news_df[['headline', 'sentiment']].head(10)\n",
    "display(sample_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7fd37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily average sentiment\n",
    "print(\"Calculating daily average sentiment...\")\n",
    "\n",
    "daily_sentiment = news_df.groupby('date_normalized')['sentiment'].agg([\n",
    "    ('avg_sentiment', 'mean'),\n",
    "    ('article_count', 'count')\n",
    "]).reset_index()\n",
    "\n",
    "print(f\"Daily sentiment calculated for {len(daily_sentiment)} days\")\n",
    "print(\"\\nDaily sentiment sample:\")\n",
    "display(daily_sentiment.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing daily returns\n",
    "print(\"Computing daily returns for stock data...\")\n",
    "\n",
    "# Sort stock data by date\n",
    "stock_df = stock_df.sort_values('date_normalized')\n",
    "\n",
    "# Calculate daily percentage returns\n",
    "stock_df['daily_return'] = stock_df['Close'].pct_change() * 100\n",
    "\n",
    "# Remove first row with NaN return\n",
    "stock_returns = stock_df.dropna(subset=['daily_return'])\n",
    "\n",
    "print(\"Daily returns computation completed\")\n",
    "print(f\"Returns calculated for {len(stock_returns)} trading days\")\n",
    "print(f\"Returns statistics:\")\n",
    "print(f\"  Average daily return: {stock_returns['daily_return'].mean():.4f}%\")\n",
    "print(f\"  Min return: {stock_returns['daily_return'].min():.4f}%\")\n",
    "print(f\"  Max return: {stock_returns['daily_return'].max():.4f}%\")\n",
    "print(f\"  Std return: {stock_returns['daily_return'].std():.4f}%\")\n",
    "\n",
    "print(\"\\nStock returns sample:\")\n",
    "display(stock_returns[['date_normalized', 'Close', 'daily_return']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11863914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sentiment and returns data for correlation analysis\n",
    "print(\"Merging sentiment and returns data...\")\n",
    "\n",
    "# Inner join on normalized dates\n",
    "merged_data = pd.merge(\n",
    "    daily_sentiment,\n",
    "    stock_returns[['date_normalized', 'daily_return', 'Close']],\n",
    "    on='date_normalized',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Merged dataset created: {len(merged_data)} matching days\")\n",
    "print(f\"Date range in merged data: {merged_data['date_normalized'].min()} to {merged_data['date_normalized'].max()}\")\n",
    "\n",
    "print(\"\\nMerged data sample:\")\n",
    "display(merged_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02951b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Pearson correlation coefficient\n",
    "print(\"Calculating Pearson correlation coefficient...\")\n",
    "\n",
    "# Calculate Pearson correlation between average sentiment and daily returns\n",
    "correlation, p_value = pearsonr(\n",
    "    merged_data['avg_sentiment'], \n",
    "    merged_data['daily_return']\n",
    ")\n",
    "\n",
    "print(\"PEARSON CORRELATION RESULTS:\")\n",
    "print(f\"Correlation Coefficient: {correlation:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Sample Size: {len(merged_data)} days\")\n",
    "\n",
    "# Interpret correlation strength\n",
    "corr_strength = abs(correlation)\n",
    "if corr_strength < 0.1:\n",
    "    strength = \"negligible\"\n",
    "elif corr_strength < 0.3:\n",
    "    strength = \"weak\"\n",
    "elif corr_strength < 0.5:\n",
    "    strength = \"moderate\"\n",
    "else:\n",
    "    strength = \"strong\"\n",
    "\n",
    "print(f\"Correlation Strength: {strength}\")\n",
    "\n",
    "# Interpret statistical significance\n",
    "if p_value < 0.05:\n",
    "    print(\"Statistical Significance: SIGNIFICANT (p < 0.05)\")\n",
    "else:\n",
    "    print(\"Statistical Significance: NOT SIGNIFICANT (p >= 0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f7e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization to show correlation\n",
    "print(\"Creating correlation visualization...\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(merged_data['avg_sentiment'], merged_data['daily_return'], \n",
    "           alpha=0.6, s=50, color='blue')\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(merged_data['avg_sentiment'], merged_data['daily_return'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(merged_data['avg_sentiment'], p(merged_data['avg_sentiment']), \n",
    "         \"r--\", linewidth=2, alpha=0.8, label='Trend line')\n",
    "\n",
    "# Plot formatting\n",
    "plt.xlabel('Average Daily Sentiment', fontsize=12)\n",
    "plt.ylabel('Daily Returns (%)', fontsize=12)\n",
    "plt.title(f'Correlation between News Sentiment and Stock Returns\\nPearson r = {correlation:.4f} (p = {p_value:.4f})', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Add correlation annotation\n",
    "plt.annotate(f'r = {correlation:.4f}\\np = {p_value:.4f}\\nn = {len(merged_data)}', \n",
    "             xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8),\n",
    "             fontsize=10, ha='left', va='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Correlation visualization completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f39ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results and visualization\n",
    "print(\"Saving results...\")\n",
    "\n",
    "# Save merged data\n",
    "merged_data.to_csv('../data/correlation_results.csv', index=False)\n",
    "print(\"‚úì Merged data saved to: ../data/correlation_results.csv\")\n",
    "\n",
    "# Save visualization\n",
    "plt.savefig('../results/correlation_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Visualization saved to: ../results/correlation_analysis.png\")\n",
    "\n",
    "# Save correlation results summary\n",
    "correlation_summary = pd.DataFrame({\n",
    "    'metric': ['pearson_correlation', 'p_value', 'sample_size', 'date_range_start', 'date_range_end'],\n",
    "    'value': [correlation, p_value, len(merged_data), \n",
    "              merged_data['date_normalized'].min(), \n",
    "              merged_data['date_normalized'].max()]\n",
    "})\n",
    "correlation_summary.to_csv('../results/correlation_summary.csv', index=False)\n",
    "print(\"‚úì Correlation summary saved to: ../results/correlation_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f13a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completion Report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CORRELATION ANALYSIS - COMPLETION REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚úÖ CRITERIA IMPLEMENTATION STATUS:\")\n",
    "print(\"‚úì Normalizing dates between news and stock data - COMPLETED\")\n",
    "print(\"‚úì Performing sentiment analysis on news headlines - COMPLETED\") \n",
    "print(\"‚úì Computing daily returns - COMPLETED\")\n",
    "print(\"‚úì Calculating Pearson correlation coefficient - COMPLETED\")\n",
    "\n",
    "print(f\"\\nüìä ANALYSIS RESULTS:\")\n",
    "print(f\"   ‚Ä¢ News articles analyzed: {len(news_df):,}\")\n",
    "print(f\"   ‚Ä¢ Stock trading days: {len(stock_df):,}\")\n",
    "print(f\"   ‚Ä¢ Matching days for correlation: {len(merged_data):,}\")\n",
    "print(f\"   ‚Ä¢ Pearson Correlation Coefficient: {correlation:.4f}\")\n",
    "print(f\"   ‚Ä¢ P-value: {p_value:.4f}\")\n",
    "\n",
    "print(f\"\\nüìà SENTIMENT ANALYSIS:\")\n",
    "print(f\"   ‚Ä¢ Average headline sentiment: {news_df['sentiment'].mean():.4f}\")\n",
    "print(f\"   ‚Ä¢ Daily average sentiment range: {daily_sentiment['avg_sentiment'].min():.4f} to {daily_sentiment['avg_sentiment'].max():.4f}\")\n",
    "\n",
    "print(f\"\\nüíπ STOCK RETURNS:\")\n",
    "print(f\"   ‚Ä¢ Average daily return: {stock_returns['daily_return'].mean():.4f}%\")\n",
    "print(f\"   ‚Ä¢ Returns range: {stock_returns['daily_return'].min():.4f}% to {stock_returns['daily_return'].max():.4f}%\")\n",
    "\n",
    "print(f\"\\nüîç CORRELATION INTERPRETATION:\")\n",
    "if p_value < 0.05:\n",
    "    if correlation > 0:\n",
    "        print(\"   ‚Ä¢ Statistically significant POSITIVE correlation found\")\n",
    "        print(\"   ‚Ä¢ Higher news sentiment tends to associate with higher stock returns\")\n",
    "    else:\n",
    "        print(\"   ‚Ä¢ Statistically significant NEGATIVE correlation found\")\n",
    "        print(\"   ‚Ä¢ Higher news sentiment tends to associate with lower stock returns\")\n",
    "else:\n",
    "    print(\"   ‚Ä¢ No statistically significant correlation found\")\n",
    "    print(\"   ‚Ä¢ News sentiment and stock returns show no clear relationship\")\n",
    "\n",
    "print(f\"\\nüíæ OUTPUT FILES GENERATED:\")\n",
    "print(\"   ‚úì ../data/correlation_results.csv\")\n",
    "print(\"   ‚úì ../results/correlation_analysis.png\") \n",
    "print(\"   ‚úì ../results/correlation_summary.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUCCESSFULLY COMPLETED\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
